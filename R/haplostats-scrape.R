#####################################################################################
# Scrapes data generated from the haplostats.org query page form. The
# first part sets the different arguments required by the haplostats 
# form. To see all the arguments required by the form print the results
# stored in the 'hapl.form' object.
#
# See README.md for more detailed notes on this script.
#
#####################################################################################
library(rvest)

#===== CREATE & LOOK AT THE HAPLOSTATS PAGE/FORM =====#
url          <- "https://haplostats.org/"
hapl.session <- session(url)
hapl.form    <- html_form(hapl.session)
hapl.form


#===== ENTER HAPLOSTATS QUERY VALUES =====#
## "HLA Dataset"
# "84|NMDP.HIGHRES.1.1.0.2007-11-20|NMDP high res 2007"    # NMDP high res 2007
# "21|NMDP.FULL-COMPOSITE.1.1.0.2011-08-25|NMDP full 2011" # NMDP full 2011
dataset <- "21|NMDP.FULL-COMPOSITE.1.1.0.2011-08-25|NMDP full 2011"

## "Haplotype Loci"
# "A~C~B~DRBX~DRB1~DQB1" # A~C~B~DRBX~DRB1~DQB1
# "A~C~B~DRB1~DQB1"      # A~C~B~DRB1~DQB1
# "C~B"                  # C~B
# "A~C~B"                # A~C~B
# "A~B~DRB1"             # A~B~DRB1
# "A~C~B~DRB1"           # A~C~B~DRB1
haplotypeLoci <- "A~C~B~DRB1~DQB1" 

## "HLA type"
a1 <- "01:01"
a2 <- "01:02"
b1 <- "08:01"
b2 <- "08:01"
c1 <- NULL
c2 <- NULL
drb1_1 <- "03:01"
drb1_2 <- "15:01"
dqb1_1 <- NULL
dqb1_2 <- NULL
drb3_1 <- NULL
drb3_2 <- NULL
drb4_1 <- NULL
drb4_2 <- NULL
drb5_1 <- NULL
drb5_2 <- NULL

#===== FILL VALUES INTO THE HAPLOSTATS FORM & SUBMIT FORM =====#
# If we wanted to set values for the 'Population' checkboxes we would
# include those arguments here (although I haven't tested how to do so).
filled.form <- html_form_set(form = hapl.form[[1]], 
                          "dataset" = dataset,
                          "haplotypeLoci" = haplotypeLoci,
                          "a1" = a1,
                          "a2" = a2,
                          "b1" = b1,
                          "b2" = b2,
                          "c1" = c1,
                          "c2" = c2,
                          "drb11" = drb1_1,
                          "drb12" = drb1_2,
                          "dqb11" = dqb1_1,
                          "dqb12" = dqb1_2,
                          "drb31" = drb3_1,
                          "drb32" = drb3_2,
                          "drb41" = drb4_1,
                          "drb42" = drb4_2,
                          "drb51" = drb5_1,
                          "drb52" = drb5_2)
hapl.page <- session_submit(x = hapl.session, form = filled.form, submit = "_eventId_success")

#===== EXTRACT DATA FROM PAGE GENERATED BY OUR SUBMISSION =====#
# structure whatever object submit_form creates to something more amenable to html parsing
hapl.html <- read_html(hapl.page) 

# After some googling I think want to use is 'CSS selectors' in parsing/navigating our HTML page.
# For example
#   * If we want to select elements with 'class="XYZ"' then we'd write ".XYZ", i.e. 
#     html_elements(hapl.html, ".display") will return elements of class=".display" (I think...).
#   * If we want to select elements with 'id="ABC"' then we'd write "#ABC", i.e.
#     html_elements(hapl.html, "#pairedFrequencies") will return elements of id="pairedFrequencies".
# See https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors for more details on
# these kinds of selectors and their notation (rvest "implements the majority of CSS3 selectors").

# PHASED GENOTYPES
hapl.elem.p <- html_elements(hapl.html, "#pairedFrequencies") 
# UNPHASED GENOTYPES
hapl.elem.u <- html_elements(hapl.html, "#mugFrequencies")

#Extract the data from the element using xml2
data = unlist(as_list(hapl.elem.u))
# This identifies the beginning of blocks of haplotypes
resultIndex = which(data %in% 'HLA Type')
# A loop to paste together the results on each line
#not sure how it behaves with manycolumns of results
for (i in resultIndex){
  print(paste(c('Haplotype:', paste(data[(i+3):(i+12)], collapse=' '), 'Type freq:',as.numeric(data[i+13]), 'Likelihood:',as.numeric(strsplit(data[i+14], '%'))), collapse=' '))
}

# if we want the 'raw text' instead of letting rvest try to automatically make it into a table
hapl.txt.p <- html_text2(hapl.elem.p) # NOTE TO SELF: Maybe try using strsplit on "\n" or "\t"?
hapl.txt.u <- html_text2(hapl.elem.u)

# try letting rvest put it in a table and see how well it does with the format
# treat blank, "NA" and "N/A" cell values as NA
hapl.tab.p <- html_table(hapl.elem.p, na.strings = c("", "NA", "N/A"))
hapl.tab.u <- html_table(hapl.elem.u, na.strings = c("", "NA", "N/A"))

####################### EXPLORING HOW TO CLEAN THE DATA #########################
# Anything beyond here is likely just tests. We still need to figure out how to
# manipulate the 'raw' data (either the the hapl.txt and hapl.tab object, whichever
# is easier to work with) into a format that is more amenable to data analysis.
#
# It's not clear to me exactly how rvest is taking the raw html structure and
# putting it into the txt/tab objects, but it is clear that it's unbelievably
# messy and will need either some clever tricks to reliably pipe the data
# into a matrix/list/whatever.
#
# It is likely that we will have to do some string manipulation to clean up
# the data (see the "stringr" and "stringi" libraries, I'm sure there ar eother
# useful tools out there for string manipulation/web scraping/general data wrangling).
# It may be a good idea to investigate whether a clever set of regex can 
# accomplish this job (or a part of it). 



##### BELOW IS TESTING GARBAGE

su1 <- unlist(strsplit(hapl.txt.u, split = c("\n", "\t")))
su2 <- unlist(strsplit(su1, split = "\t"))
su2[su2 != ""]

su[!(su %in% c("", "\n", "\t"))]

str(su)




#
#
x1 <- html_table(hapl.elem.u, header = F, fill = T)
x2 <- as.matrix(x1[[1]])
x3 <- t(x2)
str(x3)
x <- t(as.data.frame(x[[1]]))
str(x)

library(XML)
y <- XML::readHTMLTable(hapl.html)
str(y)
hapl.mat.p <- as.matrix(hapl.tab.p[[1]])
hapl.mat.u <- as.matrix(hapl.tab.u[[1]])
hapl.mat.p
hapl.mat.u





